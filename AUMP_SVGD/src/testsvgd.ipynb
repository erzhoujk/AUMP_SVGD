{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm, trange\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkernel\u001b[39;00m \u001b[39mimport\u001b[39;00m RBF\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mTmy_svgd\u001b[39;00m \u001b[39mimport\u001b[39;00m tmySVGD\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msvgd\u001b[39;00m \u001b[39mimport\u001b[39;00m SVGD\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39margparse\u001b[39;00m\n",
      "File \u001b[0;32m~/SVGD/SVGD_code/GSVGD-main/src/Tmy_svgd.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm, trange\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkernel\u001b[39;00m \u001b[39mimport\u001b[39;00m RBF\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39margparse\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmemory_profiler\u001b[39;00m \u001b[39mimport\u001b[39;00m profile\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import autograd.numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from kernel import RBF\n",
    "from Tmy_svgd import tmySVGD\n",
    "\n",
    "from svgd import SVGD\n",
    "import argparse\n",
    "from mysvgd import mySVGD\n",
    "from utils import plot_particles\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Running xshaped experiment.')\n",
    "\n",
    "parser.add_argument('--dim', type=int, default=9, help='dimension')\n",
    "\n",
    "parser.add_argument('--effdim', type=int, default=-1, help='dimension')\n",
    "parser.add_argument('--lr', type=float, default=0.01, help='learning rate')\n",
    "parser.add_argument('--delta', type=float,default=0.01,help='stepsize for projections')\n",
    "parser.add_argument('--T', type=float, default=1e-4, help='noise multiplier for projections')\n",
    "parser.add_argument('--lr_g', type=float, default=0.1, help='learning rate for g')\n",
    "parser.add_argument('--nparticles', type=int,default=50, help='no. of particles')\n",
    "parser.add_argument('--epochs', type=int, default=20000, help='no. of epochs')\n",
    "parser.add_argument('--metric', type=str, default=\"energy\", help='distance metric')\n",
    "parser.add_argument('--noise', type=str, default=\"True\", help='whether to add noise')\n",
    "parser.add_argument('--kernel', type=str, default=\"rbf\", help='kernel')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--seed', type=int, default=235, help='random seed')\n",
    "parser.add_argument('--suffix', type=str, default=\"\", help='suffix for res folder')\n",
    "parser.add_argument('--m', type=int, help='no. of projections')\n",
    "parser.add_argument('--save_every', type=int, default=200, help='step intervals to save particles')\n",
    "parser.add_argument('--method', type=str, default=\"all\", help='which method to use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])\n",
    "dim = args.dim\n",
    "lr = args.lr\n",
    "lr_gsvgd = args.lr\n",
    "delta = args.delta\n",
    "T = args.T\n",
    "nparticles = args.nparticles\n",
    "epochs = args.epochs\n",
    "seed = args.seed\n",
    "eff_dims = [args.effdim] if args.effdim > 0 else [1, 2, 5]\n",
    "save_every = args.save_every # save metric values\n",
    "print(f\"Running for dim: {dim}, lr: {lr}, nparticles: {nparticles}\")\n",
    "\n",
    "device = torch.device(f'cuda:{args.gpu}' if args.gpu != -1 else 'cpu')\n",
    "\n",
    "metric = args.metric\n",
    "Kernel = RBF\n",
    "kernel = Kernel(method=\"med_heuristic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Device: {device}\")\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "## target density\n",
    "means = torch.zeros(dim, device=device)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "'''A\n",
    "A = torch.randn(dim,dim).to('cuda') * 0.9\n",
    "A = torch.matmul(A, A.T)\n",
    "\n",
    "m = torch.max(A) \n",
    "B = torch.eye(dim).to('cuda') * m + 0.1\n",
    "diag = torch.diag(A)\n",
    "cov = A + B'''\n",
    "\n",
    "cov = torch.eye(dim, device=device)\n",
    "\n",
    "distribution = D.MultivariateNormal(means.to(device), cov)\n",
    "\n",
    "# sample from target (for computing metric)\n",
    "x_target = distribution.sample((nparticles, ))\n",
    "# sample from variational density\n",
    "torch.manual_seed(235)\n",
    "x_init = 2 + np.sqrt(2) * torch.randn(nparticles, *distribution.event_shape, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVGD\n",
    "Kernel = RBF\n",
    "if args.method in [\"SVGD\", \"all\"]:\n",
    "    print(\"Running SVGD\")\n",
    "    # sample from variational density\n",
    "    x = x_init.clone().to(device)\n",
    "    kernel = Kernel(method=\"med_heuristic\")\n",
    "    svgd = SVGD(distribution, kernel, optim.Adam([x], lr=lr), device=device)\n",
    "   \n",
    "    svgd.fit(x, epochs, verbose=True, save_every=save_every)\n",
    "    \n",
    "\n",
    "    # plot particles\n",
    "    fig_svgd = plot_particles(\n",
    "        x_init.detach(), \n",
    "        x.detach(), \n",
    "        distribution, \n",
    "        d=6.0, \n",
    "        step=0.1, \n",
    "        concat=means[2:]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta  = x\n",
    "index_svgd = []\n",
    "samn_svgd = []\n",
    "for i in range(theta.shape[0]):\n",
    "    samn_svgd.append(torch.linalg.norm(theta[i,:].cpu()).item())\n",
    "    index_svgd.append(i)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(index_svgd, samn_svgd, c='blue')\n",
    "cov_svgd = torch.cov(theta.T)\n",
    "print(torch.linalg.norm(cov - cov_svgd))\n",
    "print(cov_svgd)\n",
    "print(cov - cov_svgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running tmySVGD\")\n",
    "\n",
    "def score(X):\n",
    "        X_cp = X.clone().detach().requires_grad_()\n",
    "        log_prob = distribution.log_prob(X_cp)\n",
    "        score_func = autograd.grad(log_prob.sum(), X_cp)[0]\n",
    "        return score_func\n",
    "\n",
    "\n",
    "# sample from variational density\n",
    "res = []\n",
    "rres = []\n",
    "steps = []\n",
    "lr = 0.01\n",
    "x0 = torch.randn(nparticles, dim)\n",
    "vector1  = torch.randn(nparticles, dim).to('cuda')\n",
    "\n",
    "for i in trange(20):\n",
    "    \n",
    "    theta, vector = tmySVGD(kernel).update(x0, score,  k = 2, n_iter = 50,  debug = False, lr= lr, vector=vector1)\n",
    "    #mean = np.mean(theta, axis=0)  + np.random.random(1)\n",
    "    #var_theta = np.cov(theta.T) + np.random.random(1)\n",
    "    #x0 = np.random.multivariate_normal(mean, var_theta,num)\n",
    "    x0 = theta\n",
    "    vector1 = vector\n",
    "    \n",
    "    # res.append(np.linalg.norm(theta)/D)\n",
    "    \n",
    "    mean_svgd = torch.mean(theta, axis=0)\n",
    "\n",
    "    var_svgd = torch.cov(theta.T) \n",
    "    res.append(torch.linalg.norm(mean_svgd).item())\n",
    "    rres.append(torch.linalg.norm(var_svgd).item()) \n",
    "    if i % 20 == 0:\n",
    "        print(theta.shape)\n",
    "        print(torch.linalg.norm(cov- var_svgd) )\n",
    "        print(torch.linalg.norm(mean_svgd - means))\n",
    "    \n",
    "leng = len(res)\n",
    "x = np.arange(1,leng+1)\n",
    "plt.figure(1)\n",
    "plt.plot(x,res)\n",
    "plt.figure(2)\n",
    "plt.plot(x,rres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_svgd = plot_particles(\n",
    "        x_init.detach(), \n",
    "        theta.detach(), \n",
    "        distribution, \n",
    "        d=6.0, \n",
    "        step=0.1, \n",
    "        concat=means[2:]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running mySVGD\")\n",
    "\n",
    "def score(X):\n",
    "        X_cp = X.clone().detach().requires_grad_()\n",
    "        log_prob = distribution.log_prob(X_cp)\n",
    "        score_func = autograd.grad(log_prob.sum(), X_cp)[0]\n",
    "        return score_func\n",
    "\n",
    "\n",
    "# sample from variational density\n",
    "res = []\n",
    "rres = []\n",
    "steps = []\n",
    "lr = 0.01\n",
    "x0 = x_init\n",
    "vector1  = torch.randn(nparticles, dim).to(device)\n",
    "\n",
    "for i in trange(25):\n",
    "    \n",
    "    theta, vector = mySVGD().update(x0, score,  k = 2, n_iter = 50,  debug = False, lr= lr, vector=vector1, device=device)\n",
    "    #mean = np.mean(theta, axis=0)  + np.random.random(1)\n",
    "    #var_theta = np.cov(theta.T) + np.random.random(1)\n",
    "    #x0 = np.random.multivariate_normal(mean, var_theta,num)\n",
    "    x0 = theta\n",
    "    vector1 = vector\n",
    "    \n",
    "    # res.append(np.linalg.norm(theta)/D)\n",
    "    \n",
    "    mean_svgd = torch.mean(theta, axis=0)\n",
    "\n",
    "    var_svgd = torch.cov(theta.T) \n",
    "    res.append(torch.linalg.norm(mean_svgd).item())\n",
    "    rres.append(torch.linalg.norm(var_svgd).item()) \n",
    "    if i % 20 == 0:\n",
    "        \n",
    "        print(torch.linalg.norm(cov- var_svgd) )\n",
    "        print(torch.linalg.norm(mean_svgd - means))\n",
    "    \n",
    "leng = len(res)\n",
    "x = np.arange(1,leng+1)\n",
    "plt.figure(1)\n",
    "plt.plot(x,res)\n",
    "plt.figure(2)\n",
    "plt.plot(x,rres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_svgd = plot_particles(\n",
    "        x_init.detach(), \n",
    "        theta.detach(), \n",
    "        distribution, \n",
    "        d=6.0, \n",
    "        step=0.1, \n",
    "        concat=means[2:]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('AG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28e57e6ed411ebe457d9d5e52f3313a26a0295904f732baf128c9b6661c268ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
