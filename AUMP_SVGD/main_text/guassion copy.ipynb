{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhoujk/anaconda3/envs/AG/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tmySVGD' from 'src.Tmy_svgd' (/home/zhoujk/SVGD/SVGD_code/GSVGD-main/src/Tmy_svgd.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributions\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mD\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mTmy_svgd\u001b[39;00m \u001b[39mimport\u001b[39;00m tmySVGD\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msvgd\u001b[39;00m \u001b[39mimport\u001b[39;00m SVGD\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgsvgd\u001b[39;00m \u001b[39mimport\u001b[39;00m FullGSVGDBatch\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'tmySVGD' from 'src.Tmy_svgd' (/home/zhoujk/SVGD/SVGD_code/GSVGD-main/src/Tmy_svgd.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.distributions as D\n",
    "from src.Tmy_svgd import etmySVGD\n",
    "from src.svgd import SVGD\n",
    "from src.gsvgd import FullGSVGDBatch\n",
    "from src.kernel import RBF, BatchRBF\n",
    "from src.utils import plot_particles\n",
    "\n",
    "from src.manifold import Grassmann\n",
    "from src.s_svgd import SlicedSVGD\n",
    "from src.mysvgd import mySVGD\n",
    "from src.rand_mysvgd import min_mySVGD\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import autograd.numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch.distributions as D\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Running xshaped experiment.')\n",
    "d = 180\n",
    "parser.add_argument('--dim', type=int, default=d, help='dimension')\n",
    "s = 2000\n",
    "parser.add_argument('--effdim', type=int, default=-1, help='dimension')\n",
    "parser.add_argument('--lr', type=float, default=0.01, help='learning rate')\n",
    "parser.add_argument('--delta', type=float,default=0.01,help='stepsize for projections')\n",
    "parser.add_argument('--T', type=float, default=1e-4, help='noise multiplier for projections')\n",
    "parser.add_argument('--lr_g', type=float, default=0.1, help='learning rate for g')\n",
    "parser.add_argument('--nparticles', type=int,default=s, help='no. of particles')\n",
    "parser.add_argument('--epochs', type=int, default=1000000000000, help='no. of epochs')\n",
    "parser.add_argument('--metric', type=str, default=\"energy\", help='distance metric')\n",
    "parser.add_argument('--noise', type=str, default=\"True\", help='whether to add noise')\n",
    "parser.add_argument('--kernel', type=str, default=\"rbf\", help='kernel')\n",
    "parser.add_argument('--gpu', type=int, default=3, help='gpu')\n",
    "parser.add_argument('--seed', type=int, default=235, help='random seed')\n",
    "parser.add_argument('--suffix', type=str, default=\"\", help='suffix for res folder')\n",
    "parser.add_argument('--m', type=int, help='no. of projections')\n",
    "parser.add_argument('--save_every', type=int, default=200, help='step intervals to save particles')\n",
    "parser.add_argument('--method', type=str, default=\"all\", help='which method to use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])\n",
    "dim = args.dim\n",
    "lr = args.lr\n",
    "lr_gsvgd = args.lr\n",
    "delta = args.delta\n",
    "T = args.T\n",
    "nparticles = args.nparticles\n",
    "epochs = args.epochs\n",
    "seed = args.seed\n",
    "eff_dims = [args.effdim] if args.effdim > 0 else [1, 2, 5]\n",
    "save_every = args.save_every # save metric values\n",
    "print(f\"Running for dim: {dim}, lr: {lr}, nparticles: {nparticles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f'cuda:{args.gpu}' if args.gpu != -1 else 'cpu')\n",
    "\n",
    "metric = args.metric\n",
    "\n",
    "results_folder = f\"./res/gaussian{args.suffix}/{args.kernel}_epoch{epochs}_lr{lr}_delta{delta}_n{nparticles}_dim{dim}\"\n",
    "results_folder = f\"{results_folder}/seed{seed}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "if args.kernel == \"rbf\":\n",
    "    Kernel = RBF\n",
    "    BatchKernel = BatchRBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comm_func_eval(samples, ground_truth):\n",
    "\n",
    "    samples = samples.clone()\n",
    "    ground_truth = ground_truth.clone()\n",
    "\n",
    "    def ex():\n",
    "        f0 = torch.mean(samples, axis=0)\n",
    "        f1 = torch.mean(ground_truth, axis=0)\n",
    "        return torch.mean((f0-f1)**2)\n",
    "\n",
    "    def exsqr():\n",
    "        f0 = torch.var(samples, axis=0)\n",
    "        f1 = torch.var(ground_truth, axis=0)\n",
    "        return torch.mean((f0-f1)**2)\n",
    "\n",
    "\n",
    "    out = {}\n",
    "    out['mean_dis'] = ex()\n",
    "    out['var_dis'] = exsqr()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Device: {device}\")\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "## target density\n",
    "means = torch.zeros(dim, device=device)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "'''A\n",
    "A = torch.randn(dim,dim).to('cuda') * 0.9\n",
    "A = torch.matmul(A, A.T)\n",
    "\n",
    "m = torch.max(A) \n",
    "B = torch.eye(dim).to('cuda') * m + 0.1\n",
    "diag = torch.diag(A)\n",
    "cov = A + B'''\n",
    "\n",
    "cov = torch.eye(dim, device=device)\n",
    "\n",
    "distribution = D.MultivariateNormal(means.to(device), cov)\n",
    "\n",
    "# sample from target (for computing metric)\n",
    "x_target = distribution.sample((nparticles, ))\n",
    "# sample from variational density\n",
    "torch.manual_seed(235)\n",
    "x_init = 2 + np.sqrt(2) * torch.randn(nparticles, *distribution.event_shape, device=device)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVGD\n",
    "if args.method in [\"SVGD\", \"all\"]:\n",
    "    print(\"Running SVGD\")\n",
    "    # sample from variational density\n",
    "    x = x_init.clone().to(device)\n",
    "    kernel = Kernel(method=\"med_heuristic\")\n",
    "    svgd = SVGD(distribution, kernel, optim.Adam([x], lr=lr), device=device)\n",
    "    start = time.time()\n",
    "    svgd.fit(x, epochs, verbose=True, save_every=save_every)\n",
    "    elapsed_time_svgd = time.time() - start\n",
    "\n",
    "    # plot particles\n",
    "    fig_svgd = plot_particles(\n",
    "        x_init.detach(), \n",
    "        x.detach(), \n",
    "        distribution, \n",
    "        d=6.0, \n",
    "        step=0.1, \n",
    "        concat=means[2:],\n",
    "        savedir=results_folder + f\"/svgd.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta  = x\n",
    "index_svgd = []\n",
    "samn_svgd = []\n",
    "for i in range(theta.shape[0]):\n",
    "    samn_svgd.append(torch.linalg.norm(theta[i,:].cpu()).item())\n",
    "    index_svgd.append(i)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(index_svgd, samn_svgd, c='blue')\n",
    "cov_svgd = torch.cov(theta.T)\n",
    "print(torch.linalg.norm(cov - cov_svgd))\n",
    "\n",
    "print(comm_func_eval(theta, x_target))\n",
    "print(torch.trace(cov - cov_svgd))\n",
    "(evals, evecs) = torch.linalg.eig(cov - cov_svgd)\n",
    "print(evals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running min_mySVGD\")\n",
    "\n",
    "\n",
    "def score(X):\n",
    "        X_cp = X.clone().detach().requires_grad_()\n",
    "        log_prob = distribution.log_prob(X_cp)\n",
    "        score_func = autograd.grad(log_prob.sum(), X_cp)[0]\n",
    "        return score_func\n",
    "\n",
    "\n",
    "# sample from variational density\n",
    "res = []\n",
    "rres = []\n",
    "steps = []\n",
    "lr = 0.1\n",
    "x0 = x_init\n",
    "vector1  = torch.randn(nparticles, dim).to(device)\n",
    "model  = tmySVGD(kernel, device)\n",
    "\n",
    "    \n",
    "theta, vector = model.update(x0, score,  k = 2, n_iter =5000,  debug = False, lr= lr, vector=vector1)\n",
    "    #mean = np.mean(theta, axis=0)  + np.random.random(1)\n",
    "    #var_theta = np.cov(theta.T) + np.random.random(1)\n",
    "    #x0 = np.random.multivariate_normal(mean, var_theta,num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_svgd = []\n",
    "samn_svgd = []\n",
    "for i in range(theta.shape[0]):\n",
    "    samn_svgd.append(torch.linalg.norm(theta[i,:].cpu()).item())\n",
    "    index_svgd.append(i)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(index_svgd, samn_svgd, c='blue')\n",
    "cov_mysvgd = torch.cov(theta.T)\n",
    "print(torch.linalg.norm(cov - cov_mysvgd))\n",
    "print(comm_func_eval(theta, x_target))\n",
    "print(torch.trace(cov - cov_mysvgd))\n",
    "(evals, evecs) = torch.linalg.eig(cov - cov_mysvgd)\n",
    "print(evals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_svgd = plot_particles(\n",
    "        x_init.detach(), \n",
    "        theta.detach(), \n",
    "        distribution, \n",
    "        d=6.0, \n",
    "        step=0.1, \n",
    "        concat=means[2:]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GSVGD\n",
    "if args.method in [\"GSVGD\", \"all\"]:\n",
    "    res_gsvgd = [0] * len(eff_dims)\n",
    "    def run_gsvgd(eff_dims):\n",
    "        for i, eff_dim in enumerate(eff_dims):\n",
    "            print(f\"Running GSVGD with eff dim = {eff_dim}\")\n",
    "\n",
    "            if args.m is None:\n",
    "                m = min(20, dim // eff_dim)\n",
    "            elif args.m == -1:\n",
    "                m = dim // eff_dim\n",
    "            else:\n",
    "                m = args.m\n",
    "            print(\"number of projections:\", m)\n",
    "\n",
    "            # sample from variational density\n",
    "            x_init_gsvgd = x_init.clone()\n",
    "            x_gsvgd = x_init_gsvgd.clone()\n",
    "\n",
    "            kernel_gsvgd = BatchKernel(method=\"med_heuristic\")\n",
    "            optimizer = optim.Adam([x_gsvgd], lr=lr_gsvgd)\n",
    "            manifold = Grassmann(dim, eff_dim)\n",
    "            U = torch.eye(dim).requires_grad_().to(device)\n",
    "            U = U[:, :(m*eff_dim)]\n",
    "\n",
    "            gsvgd = FullGSVGDBatch(\n",
    "                target=distribution,\n",
    "                kernel=kernel_gsvgd,\n",
    "                manifold=manifold,\n",
    "                optimizer=optimizer,\n",
    "                delta=delta,\n",
    "                T=T,\n",
    "                device=device\n",
    "            )\n",
    "            start = time.time()\n",
    "            U, metric_gsvgd = gsvgd.fit(x_gsvgd, U, m, epochs, \n",
    "                verbose=True, save_every=save_every, threshold=0.0001*m)\n",
    "            elapsed_time = time.time() - start\n",
    "\n",
    "            # plot particles\n",
    "            fig_gsvgd = plot_particles(\n",
    "                x_init_gsvgd.detach(), \n",
    "                x_gsvgd.detach(), \n",
    "                distribution, \n",
    "                d=6.0, \n",
    "                step=0.1, \n",
    "                concat=means[2:],\n",
    "                savedir=results_folder + f\"/fullgsvgd_effdim{eff_dim}_lr{lr_gsvgd}_delta{delta}_m{m}_T{T}.png\"\n",
    "            )\n",
    "\n",
    "            # store results\n",
    "            res_gsvgd[i] = {\"init\":x_init_gsvgd, \"final\":x_gsvgd, \"metric\":metric_gsvgd, \n",
    "                \"fig\":fig_gsvgd, \"particles\":gsvgd.particles, \"pam\":gsvgd.pam, \"res\": gsvgd,\n",
    "                \"elapsed_time\": elapsed_time}\n",
    "        return res_gsvgd, x_gsvgd\n",
    "\n",
    "    res_gsvgd, x_gsvgd = run_gsvgd(eff_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta  = x_gsvgd\n",
    "index_svgd = []\n",
    "samn_svgd = []\n",
    "for i in range(theta.shape[0]):\n",
    "    samn_svgd.append(torch.linalg.norm(theta[i,:].cpu()).item())\n",
    "    index_svgd.append(i)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(index_svgd, samn_svgd, c='blue')\n",
    "cov_gsvgd = torch.cov(theta.T)\n",
    "print(torch.linalg.norm(cov - cov_gsvgd))\n",
    "print(comm_func_eval(theta, x_target))\n",
    "print(torch.trace(cov - cov_gsvgd))\n",
    "(evals, evecs) = torch.linalg.eig(cov - cov_gsvgd)\n",
    "print(evals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "## S-SVGD\n",
    "if args.method in [\"S-SVGD\", \"all\"]:\n",
    "    print(\"Running S-SVGD\")\n",
    "    # sample from variational density\n",
    "    x_init_s_svgd = x_init.clone()\n",
    "    x_s_svgd = x_init_s_svgd.clone().requires_grad_()\n",
    "    s_svgd = SlicedSVGD(distribution, device=device)\n",
    "\n",
    "    start = time.time()\n",
    "    x_s_svgd, metric_s_svgd = s_svgd.fit(\n",
    "        samples=x_s_svgd, \n",
    "        n_epoch=epochs, \n",
    "        lr=args.lr_g,\n",
    "        eps=lr,\n",
    "        save_every=save_every\n",
    "    )\n",
    "    elapsed_time_s_svgd = time.time() - start\n",
    "\n",
    "    # plot particles\n",
    "    fig_s_svgd = plot_particles(\n",
    "        x_init_s_svgd.detach(), \n",
    "        x_s_svgd.detach(), \n",
    "        distribution, \n",
    "        d=6.0, \n",
    "        step=0.1, \n",
    "        concat=means[2:],\n",
    "        savedir=results_folder + f\"/ssvgd_lr{lr}_lrg{args.lr_g}.png\"\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta  = x_s_svgd\n",
    "index_svgd = []\n",
    "samn_svgd = []\n",
    "for i in range(theta.shape[0]):\n",
    "    samn_svgd.append(torch.linalg.norm(theta[i,:].cpu()).item())\n",
    "    index_svgd.append(i)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(index_svgd, samn_svgd, c='blue')\n",
    "cov_ssvgd = torch.cov(theta.T)\n",
    "print(torch.linalg.norm(cov - cov_ssvgd))\n",
    "print(comm_func_eval(theta, x_target))\n",
    "print(torch.trace(cov - cov_ssvgd))\n",
    "(evals, evecs) = torch.linalg.eig(cov - cov_ssvgd)\n",
    "print(evals[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('AG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28e57e6ed411ebe457d9d5e52f3313a26a0295904f732baf128c9b6661c268ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
