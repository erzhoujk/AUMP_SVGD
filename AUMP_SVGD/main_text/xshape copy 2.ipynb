{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import autograd.numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.Tmy_svgd import etmySVGD\n",
    "import torch.optim as optim\n",
    "import torch.distributions as D\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "#from src.rand_mysvgd import min_mySVGD\n",
    "import matplotlib.pyplot as plt\n",
    "from src.svgd import SVGD\n",
    "from src.gsvgd import FullGSVGDBatch\n",
    "from src.kernel import RBF, BatchRBF\n",
    "from src.utils import plot_particles\n",
    "\n",
    "from src.manifold import Grassmann\n",
    "from src.s_svgd import SlicedSVGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint() received an invalid combination of arguments - got (int), but expected one of:\n * (int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m list_energy \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39m5\u001b[39m,\u001b[39m20\u001b[39m, \u001b[39m7\u001b[39m)\n\u001b[1;32m      6\u001b[0m list_norm[\u001b[39m2\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m5\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m7\u001b[39m\n\u001b[0;32m----> 7\u001b[0m torch\u001b[39m.\u001b[39;49mrandint(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: randint() received an invalid combination of arguments - got (int), but expected one of:\n * (int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "list_norm = torch.zeros(5,20, 7)\n",
    "list_gr_var = torch.zeros(5,20, 7)\n",
    "list_tr = torch.zeros(5,20, 7)\n",
    "list_eig = torch.zeros(5,20, 7)\n",
    "list_energy = torch.zeros(5,20, 7)\n",
    "list_norm[2,10,5] = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Sliced_KSD_Clean.Util import *\n",
    "from src.Sliced_KSD_Clean.Divergence.Def_Divergence import *\n",
    "from src.Sliced_KSD_Clean.Divergence.Kernel import *\n",
    "from src.Sliced_KSD_Clean.Divergence.Dataloader import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.distributions as D\n",
    "from tqdm import tqdm, trange\n",
    "from src.svgd import SVGD\n",
    "from src.gsvgd import FullGSVGDBatch\n",
    "from src.kernel import RBF, BatchRBF\n",
    "from src.utils import plot_particles\n",
    "\n",
    "from src.manifold import Grassmann\n",
    "from src.s_svgd import SlicedSVGD\n",
    "from src.mysvgd import mySVGD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--method'], dest='method', nargs=None, const=None, default='all', type=<class 'str'>, choices=None, required=False, help='which method to use', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Running xshaped experiment.')\n",
    "hao = 10 \n",
    "parser.add_argument('--dim', type=int,default=10,help='dimension')\n",
    "parser.add_argument('--effdim', type=int, default=3, help='dimension')\n",
    "parser.add_argument('--lr', type=float,default=0.01,help='learning rate')\n",
    "parser.add_argument('--lr_g', type=float, default=0.1, help='learning rate for g')\n",
    "parser.add_argument('--delta', type=float,default=0.01, help='stepsize for projections')\n",
    "parser.add_argument('--T', type=float, default=1e-4, help='noise multiplier for projections')\n",
    "parser.add_argument('--nparticles', type=int, default=200, help='no. of particles')\n",
    "parser.add_argument('--epochs', type=int,default=20000, help='no. of epochs')\n",
    "parser.add_argument('--metric', type=str, default=\"energy\", help='distance metric')\n",
    "parser.add_argument('--noise', type=str, default=\"True\", help='whether to add noise')\n",
    "parser.add_argument('--kernel', type=str, default=\"rbf\", help='kernel')\n",
    "parser.add_argument('--gpu', type=int, default=4, help='gpu')\n",
    "parser.add_argument('--seed', type=int, default=0, help='random seed') \n",
    "parser.add_argument('--suffix', type=str, default=\"\", help='suffix for res folder')\n",
    "parser.add_argument('--m', type=int, help='no. of projections')\n",
    "parser.add_argument('--save_every', type=int, default=200, help='step intervals to save particles')\n",
    "parser.add_argument('--method', type=str, default=\"all\", help='which method to use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for dim: 10, lr: 0.01, nparticles: 200\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args([])\n",
    "dim = args.dim\n",
    "lr = args.lr\n",
    "delta = args.delta\n",
    "T = args.T\n",
    "nparticles = args.nparticles\n",
    "epochs = args.epochs\n",
    "seed = args.seed\n",
    "eff_dims = [args.effdim] if args.effdim > 0 else [1, 2, 5]\n",
    "add_noise = True if args.noise == \"True\" else False\n",
    "correlation = 0.95\n",
    "save_every = args.save_every\n",
    "print(f\"Running for dim: {dim}, lr: {lr}, nparticles: {nparticles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(f'cuda:{args.gpu}' if args.gpu != -1 else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comm_func_eval(samples, ground_truth):\n",
    "\n",
    "    samples = samples.clone()\n",
    "    ground_truth = ground_truth.clone()\n",
    "\n",
    "    def ex():\n",
    "        f0 = torch.mean(samples, axis=0)\n",
    "        f1 = torch.mean(ground_truth, axis=0)\n",
    "        return torch.mean((f0-f1)**2)\n",
    "\n",
    "    def exsqr():\n",
    "        f0 = torch.var(samples, axis=0)\n",
    "        f1 = torch.var(ground_truth, axis=0)\n",
    "        return torch.mean((f0-f1)**2)\n",
    "\n",
    "\n",
    "    out = {}\n",
    "    out['mean_dis'] = ex()\n",
    "    out['var_dis'] = exsqr()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xshaped_gauss_experiment(mixture_dist, means, correlation):\n",
    "    '''Mixture of Multivariate gaussian with cov matrices being the identity.\n",
    "    Args:\n",
    "        mixture_dist: torch.distributions.Categorical-like instance for the \n",
    "            probability of each component in the mixture.\n",
    "        means: Tensor of shape (nmix, d), where nmix is the number of components \n",
    "            and d is the dimension of each component.\n",
    "        correlation: Float between 0 and 1 for the magnitude of correlation between\n",
    "            the first two dims.\n",
    "    '''\n",
    "    nmix, dim = means.shape\n",
    "    \n",
    "    # create multibatch multivariate Gaussian\n",
    "    cov1 = torch.eye(dim, device=device)\n",
    "    cov1[:2, :2] = torch.Tensor([[1, correlation], [correlation, 1]])\n",
    "    cov2 = torch.eye(dim, device=device)\n",
    "    cov2[:2, :2] = torch.Tensor([[1, -correlation], [-correlation, 1]])\n",
    "    mix_cov = torch.stack((cov1, cov2))\n",
    "    comp = D.MultivariateNormal(means.to(device), mix_cov)\n",
    "\n",
    "    distribution = D.mixture_same_family.MixtureSameFamily(mixture_dist, comp)   \n",
    "    return(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = args.metric\n",
    "\n",
    "results_folder = f\"./res/xshaped{args.suffix}/{args.kernel}_epoch{epochs}_lr{lr}_delta{delta}_n{nparticles}_dim{dim}\"\n",
    "results_folder = f\"{results_folder}/seed{seed}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.kernel == \"rbf\":\n",
    "    Kernel = RBF\n",
    "    BatchKernel = BatchRBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:4\n",
      "Running SVGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:26<00:00, 231.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.2421, device='cuda:4')\n",
      "tensor(0.8128, device='cuda:4')\n",
      "tensor(44.7118, device='cuda:4')\n",
      "tensor(2.0637+0.j, device='cuda:4')\n",
      "Running SVGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:39<00:00, 201.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0097, device='cuda:4')\n",
      "tensor(0.7912, device='cuda:4')\n",
      "tensor(53.0899, device='cuda:4')\n",
      "tensor(2.0894+0.j, device='cuda:4')\n",
      "Running SVGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:39<00:00, 201.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.0967, device='cuda:4')\n",
      "tensor(0.8395, device='cuda:4')\n",
      "tensor(63.7584, device='cuda:4')\n",
      "tensor(2.3991+0.j, device='cuda:4')\n",
      "Running SVGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:38<00:00, 202.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.0507, device='cuda:4')\n",
      "tensor(0.8637, device='cuda:4')\n",
      "tensor(73.8995, device='cuda:4')\n",
      "tensor(2.5667+0.j, device='cuda:4')\n",
      "Running SVGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:45<00:00, 189.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.0772, device='cuda:4')\n",
      "tensor(0.9085, device='cuda:4')\n",
      "tensor(85.3137, device='cuda:4')\n",
      "tensor(2.8526+0.j, device='cuda:4')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Device: {device}\")\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "list_norm = []\n",
    "list_gr_var = []\n",
    "list_tr = []\n",
    "list_eig = []\n",
    "\n",
    "for dim in range(50, 100, 10):\n",
    "    ## target density\n",
    "    \n",
    "\n",
    "## target density\n",
    "    mix_means = torch.zeros((2, dim), device=device)\n",
    "    mix_means[:, :2] = 1\n",
    "\n",
    "    distribution = xshaped_gauss_experiment(\n",
    "        mixture_dist=D.Categorical(torch.ones(mix_means.shape[0], device=device)),\n",
    "        means=mix_means,\n",
    "        correlation=correlation\n",
    "    )\n",
    "\n",
    "# sample from target (for computing metric)\n",
    "    x_target = distribution.sample((nparticles, ))\n",
    "# sample from variational density\n",
    "    x_init = torch.randn(nparticles, *distribution.event_shape, device=device)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # sample from variational density\n",
    "    x_init =  torch.randn(nparticles, *distribution.event_shape).to(device)\n",
    "\n",
    "    ## SVGD\n",
    "    cov = torch.cov(x_target.T)\n",
    "\n",
    "    if args.method in [\"SVGD\", \"all\"]:\n",
    "        \n",
    "\n",
    "        print(\"Running SVGD\")\n",
    "        # sample from variational density\n",
    "        x = x_init.clone().to(device)\n",
    "        kernel = Kernel(method=\"med_heuristic\")\n",
    "        svgd = SVGD(distribution, kernel, optim.Adam([x], lr=lr), device=device)\n",
    "        \n",
    "        svgd.fit(x, epochs, verbose=True, save_every=save_every)\n",
    "        \n",
    "\n",
    "    theta = x\n",
    "        \n",
    "    del x\n",
    "\n",
    "\n",
    "    cov_svgd = torch.cov(theta.T)\n",
    "    print(torch.linalg.norm(cov - cov_svgd))\n",
    "    list_norm.append(torch.linalg.norm(cov - cov_svgd))\n",
    "    print(comm_func_eval(theta, x_target)['var_dis'])\n",
    "    list_gr_var.append(comm_func_eval(theta, x_target)['var_dis'])\n",
    "    print(torch.trace(cov - cov_svgd))\n",
    "    list_tr.append(torch.trace(cov - cov_svgd))\n",
    "    (evals, evecs) = torch.linalg.eig(cov - cov_svgd)\n",
    "    print(evals[0])\n",
    "    list_eig.append(evals[0])\n",
    "    del theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running min_mySVGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20188/30000 [1:20:34<39:09,  4.18it/s]  \n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 4; 23.69 GiB total capacity; 22.71 GiB already allocated; 2.94 MiB free; 22.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 43\u001b[0m\n\u001b[1;32m     38\u001b[0m x0 \u001b[39m=\u001b[39m x_init\n\u001b[1;32m     39\u001b[0m vector1  \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(nparticles, dim)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 43\u001b[0m theta, vector \u001b[39m=\u001b[39m tmySVGD(kernel, device)\u001b[39m.\u001b[39;49mupdate(x0,score,  k \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m, n_iter \u001b[39m=\u001b[39;49m \u001b[39m30000\u001b[39;49m,  debug \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, lr\u001b[39m=\u001b[39;49m lr, vector\u001b[39m=\u001b[39;49mvector1)\n\u001b[1;32m     44\u001b[0m    \u001b[39m#mean = np.mean(theta, axis=0)  + np.random.random(1)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m    \u001b[39m#var_theta = np.cov(theta.T) + np.random.random(1)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m    \u001b[39m#x0 = np.random.multivariate_normal(mean, var_theta,num)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m cov_mysvgd \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcov(theta\u001b[39m.\u001b[39mT)\n",
      "File \u001b[0;32m~/anaconda3/envs/AG/lib/python3.9/site-packages/memory_profiler.py:1142\u001b[0m, in \u001b[0;36mprofile.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1141\u001b[0m     prof \u001b[39m=\u001b[39m get_prof()\n\u001b[0;32m-> 1142\u001b[0m     val \u001b[39m=\u001b[39m prof(func)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1143\u001b[0m     show_results_bound(prof)\n\u001b[1;32m   1144\u001b[0m     \u001b[39mreturn\u001b[39;00m val\n",
      "File \u001b[0;32m~/anaconda3/envs/AG/lib/python3.9/site-packages/memory_profiler.py:717\u001b[0m, in \u001b[0;36mLineProfiler.wrap_function.<locals>.f\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m    716\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_count_ctxmgr():\n\u001b[0;32m--> 717\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/SVGD/SVGD_code/GSVGD-main/src/Tmy_svgd.py:126\u001b[0m, in \u001b[0;36mtmySVGD.update\u001b[0;34m(self, x0, lnprob, n_iter, k, debug, lr, vector)\u001b[0m\n\u001b[1;32m    124\u001b[0m lnpgrad_j2 \u001b[39m=\u001b[39m lnpgrad[:,j]\n\u001b[1;32m    125\u001b[0m \u001b[39m# calculating the kernel matrix\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m kxy2, repulsion2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msvgd_kernel(theta_ab2) \n\u001b[1;32m    129\u001b[0m attraction2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(kxy2, lnpgrad_j2) \n\u001b[1;32m    134\u001b[0m vec1 \u001b[39m=\u001b[39m \u001b[39m0.02\u001b[39m\u001b[39m*\u001b[39mlr\u001b[39m*\u001b[39m(attraction1 \u001b[39m+\u001b[39m repulsion1[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m theta_ab1\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/SVGD/SVGD_code/GSVGD-main/src/Tmy_svgd.py:49\u001b[0m, in \u001b[0;36mtmySVGD.svgd_kernel\u001b[0;34m(self, theta_ab)\u001b[0m\n\u001b[1;32m     47\u001b[0m Y \u001b[39m=\u001b[39m theta_ab\u001b[39m.\u001b[39mclone()\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m     48\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk\u001b[39m.\u001b[39;49mbandwidth(theta_ab, theta_ab)\n\u001b[1;32m     50\u001b[0m K_XX \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk(X_cp, Y)\n\u001b[1;32m     51\u001b[0m grad_K \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mautograd\u001b[39m.\u001b[39mgrad(K_XX\u001b[39m.\u001b[39msum(), X_cp)[\u001b[39m0\u001b[39m] \n",
      "File \u001b[0;32m~/SVGD/SVGD_code/GSVGD-main/src/kernel.py:80\u001b[0m, in \u001b[0;36mRBF.bandwidth\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m\"\"\"Compute magic bandwidth\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m dnorm2 \u001b[39m=\u001b[39m l2norm(X, Y)\n\u001b[0;32m---> 80\u001b[0m med_heuristic_sq \u001b[39m=\u001b[39m median_heuristic(dnorm2, device\u001b[39m=\u001b[39;49mX\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     81\u001b[0m sigma2 \u001b[39m=\u001b[39m med_heuristic_sq \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mlog(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m     82\u001b[0m \u001b[39m# sigma2 = med_heuristic_sq \u001b[39;00m\n",
      "File \u001b[0;32m~/SVGD/SVGD_code/GSVGD-main/src/kernel.py:43\u001b[0m, in \u001b[0;36mmedian_heuristic\u001b[0;34m(dnorm2, device)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m\"\"\"Compute median heuristic.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mInputs:\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m    dnorm2: (n x n) tensor of \\|X - Y\\|_2^2\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mReturn:\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m    med(\\|X_i - Y_j\\|_2^2, 1 \\leq i < j \\leq n)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m ind_array \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtriu(torch\u001b[39m.\u001b[39mones_like(dnorm2, device\u001b[39m=\u001b[39mdevice), diagonal\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 43\u001b[0m med_heuristic \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmedian(dnorm2[ind_array])\n\u001b[1;32m     44\u001b[0m \u001b[39m#med_heuristic = torch.Tensor(1).to('cuda')\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m med_heuristic\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 4; 23.69 GiB total capacity; 22.71 GiB already allocated; 2.94 MiB free; 22.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Running min_mySVGD\")\n",
    "\n",
    "def score(X):\n",
    "        X_cp = X.clone().detach().requires_grad_()\n",
    "        log_prob = distribution.log_prob(X_cp)\n",
    "        score_func = autograd.grad(log_prob.sum(), X_cp)[0]\n",
    "        return score_func\n",
    "\n",
    "list_norm_mysvgd = []\n",
    "list_gr_var_mysvgd = []\n",
    "list_tr_mysvgd= []\n",
    "list_eig_mysvgd = []\n",
    "\n",
    "# sample from variational density\n",
    "for dim in range(50, 100, 10):\n",
    "     mix_means = torch.zeros((2, dim), device=device)\n",
    "     mix_means[:, :2] = 1\n",
    "\n",
    "     distribution = xshaped_gauss_experiment(\n",
    "        mixture_dist=D.Categorical(torch.ones(mix_means.shape[0], device=device)),\n",
    "        means=mix_means,\n",
    "        correlation=correlation\n",
    "     )\n",
    "\n",
    "# sample from target (for computing metric)\n",
    "     x_target = distribution.sample((nparticles, ))\n",
    "# sample from variational density\n",
    "     x_init = torch.randn(nparticles, *distribution.event_shape, device=device)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "     cov = torch.cov(x_target.T)\n",
    "\n",
    "    \n",
    "     x0 = x_init\n",
    "     vector1  = torch.randn(nparticles, dim).to(device)\n",
    "\n",
    "     \n",
    "        \n",
    "     theta, vector = tmySVGD(kernel, device).update(x0,score,  k = 2, n_iter = 30000,  debug = False, lr= lr, vector=vector1)\n",
    "        #mean = np.mean(theta, axis=0)  + np.random.random(1)\n",
    "        #var_theta = np.cov(theta.T) + np.random.random(1)\n",
    "        #x0 = np.random.multivariate_normal(mean, var_theta,num)\n",
    "        \n",
    "        \n",
    "\n",
    "     cov_mysvgd = torch.cov(theta.T)\n",
    "     print(torch.linalg.norm(cov - cov_mysvgd))\n",
    "     list_norm_mysvgd.append(torch.linalg.norm(cov - cov_mysvgd))\n",
    "     print(comm_func_eval(theta, x_target)['var_dis'])\n",
    "     list_gr_var_mysvgd.append(comm_func_eval(theta, x_target)['var_dis'])\n",
    "     print(torch.trace(cov - cov_mysvgd))\n",
    "     list_tr_mysvgd.append(torch.trace(cov - cov_mysvgd))\n",
    "     (evals, evecs) = torch.linalg.eig(cov - cov_mysvgd)\n",
    "     print(evals[0])\n",
    "     list_eig_mysvgd.append(evals[0])\n",
    "     del theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cov = torch.cov(x_target.T)\n",
    "index_svgd = []\n",
    "samn_svgd = []\n",
    "for i in range(theta.shape[0]):\n",
    "    samn_svgd.append(torch.linalg.norm(theta[i,:].cpu()).item())\n",
    "    index_svgd.append(i)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(index_svgd, samn_svgd, c='blue')\n",
    "\n",
    "cov_mysvgd = torch.cov(theta.T)\n",
    "\n",
    "\n",
    "print(torch.linalg.norm(cov - cov_mysvgd))\n",
    "print(comm_func_eval(theta, x_target))\n",
    "print(torch.trace(cov - cov_mysvgd))\n",
    "(evals, evecs) = torch.linalg.eig(cov - cov_mysvgd)\n",
    "print(evals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_svgd = plot_particles(\n",
    "        x_init.detach(), \n",
    "        theta.detach(), \n",
    "        distribution, \n",
    "        d=6.0, \n",
    "        step=0.1, \n",
    "        concat=mix_means[0, 2:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GSVGD\n",
    "\n",
    "list_norm_gsvgd = []\n",
    "list_gr_var_gsvgd = []\n",
    "list_tr_gsvgd= []\n",
    "list_eig_gsvgd = []\n",
    "\n",
    "# sample from variational density\n",
    "for dim in range(50, 100, 10):\n",
    "    ## target density\n",
    "    mix_means = torch.zeros((2, dim), device=device)\n",
    "    mix_means[:, :2] = 1\n",
    "\n",
    "    distribution = xshaped_gauss_experiment(\n",
    "        mixture_dist=D.Categorical(torch.ones(mix_means.shape[0], device=device)),\n",
    "        means=mix_means,\n",
    "        correlation=correlation\n",
    "    )\n",
    "\n",
    "\n",
    "    # sample from target (for computing metric)\n",
    "    x_target = distribution.sample((nparticles, )).to(device)\n",
    "    cov = torch.cov(x_target)\n",
    "\n",
    "    # sample from variational density\n",
    "    x_init =  torch.randn(nparticles, *distribution.event_shape).to(device)\n",
    "\n",
    "    ## SVGD\n",
    "    cov = torch.cov(x_target.T)\n",
    "    if args.method in [\"GSVGD\", \"all\"]:\n",
    "        res_gsvgd = [0] * len(eff_dims)\n",
    "        def run_gsvgd(eff_dims):\n",
    "            for i, eff_dim in enumerate(eff_dims):\n",
    "                print(f\"Running GSVGD with eff dim = {eff_dim}\")\n",
    "\n",
    "                m = min(20, dim // eff_dim) if args.m is None else args.m\n",
    "                print(\"number of projections:\", m)\n",
    "\n",
    "                # sample from variational density\n",
    "                x_init_gsvgd = x_init.clone()\n",
    "                x_gsvgd = x_init_gsvgd.clone()\n",
    "\n",
    "                kernel_gsvgd = BatchKernel(method=\"med_heuristic\")\n",
    "                optimizer = optim.Adam([x_gsvgd], lr=lr)\n",
    "                manifold = Grassmann(dim, eff_dim)\n",
    "                U = torch.eye(dim, device=device).requires_grad_(True)\n",
    "                U = U[:, :(m*eff_dim)]\n",
    "\n",
    "                gsvgd = FullGSVGDBatch(\n",
    "                    target=distribution,\n",
    "                    kernel=kernel_gsvgd,\n",
    "                    manifold=manifold,\n",
    "                    optimizer=optimizer,\n",
    "                    delta=delta,\n",
    "                    T=T,\n",
    "                    device=device,\n",
    "                    noise=add_noise\n",
    "                )\n",
    "                start = time.time()\n",
    "                U, metric_gsvgd = gsvgd.fit(x_gsvgd, U, m, epochs, \n",
    "                    verbose=True, save_every=save_every, threshold=0.0001*m)\n",
    "                elapsed_time = time.time() - start\n",
    "\n",
    "                # plot particles\n",
    "                fig_gsvgd = plot_particles(\n",
    "                    x_init_gsvgd.detach(), \n",
    "                    x_gsvgd.detach(), \n",
    "                    distribution, \n",
    "                    d=9.0, \n",
    "                    step=0.1, \n",
    "                    concat=mix_means[0, 2:].to(device),\n",
    "                    savedir=results_folder + f\"/fullgsvgd_effdim{eff_dim}_lr{lr}_delta{delta}_m{m}_T{T}.png\"\n",
    "                )\n",
    "\n",
    "                # store results\n",
    "                res_gsvgd[i] = {\n",
    "                    \"init\":x_init_gsvgd, \"final\":x_gsvgd, \"metric\":metric_gsvgd, \n",
    "                    \"fig\":fig_gsvgd, \"particles\":gsvgd.particles, \"pam\":gsvgd.pam, \"res\": gsvgd,\n",
    "                    \"elapsed_time\": elapsed_time}\n",
    "            return res_gsvgd,x_gsvgd\n",
    "\n",
    "    res_gsvgd ,x_gsvgd= run_gsvgd(eff_dims)\n",
    "    theta = x_gsvgd\n",
    "    del x_gsvgd\n",
    "    cov_gsvgd = torch.cov(theta.T)\n",
    "    print(torch.linalg.norm(cov - cov_gsvgd))\n",
    "    list_norm_gsvgd.append(torch.linalg.norm(cov - cov_gsvgd))\n",
    "    print(comm_func_eval(theta, x_target)['var_dis'])\n",
    "    list_gr_var_gsvgd.append(comm_func_eval(theta, x_target)['var_dis'])\n",
    "    print(torch.trace(cov - cov_gsvgd))\n",
    "    list_tr_gsvgd.append(torch.trace(cov - cov_gsvgd))\n",
    "    (evals, evecs) = torch.linalg.eig(cov - cov_gsvgd)\n",
    "    print(evals[0])\n",
    "    list_eig_gsvgd.append(evals[0])\n",
    "\n",
    "    del theta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = x_gsvgd\n",
    "cov = torch.cov(x_target.T)\n",
    "index_svgd = []\n",
    "samn_svgd = []\n",
    "for i in range(theta.shape[0]):\n",
    "    samn_svgd.append(torch.linalg.norm(theta[i,:].cpu()).item())\n",
    "    index_svgd.append(i)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(index_svgd, samn_svgd, c='blue')\n",
    "\n",
    "cov_gsvgd = torch.cov(theta.T)\n",
    "\n",
    "\n",
    "print(torch.linalg.norm(cov - cov_gsvgd))\n",
    "print(comm_func_eval(theta, x_target))\n",
    "print(torch.trace(cov - cov_gsvgd))\n",
    "(evals, evecs) = torch.linalg.eig(cov - cov_gsvgd)\n",
    "print(evals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## S-SVGD\n",
    "list_norm_ssvgd = []\n",
    "list_gr_var_ssvgd = []\n",
    "list_tr_ssvgd = []\n",
    "list_eig_ssvgd = []\n",
    "\n",
    "for dim in range(50, 100, 10):\n",
    "    ## target density\n",
    "    mix_means = torch.zeros((2, dim), device=device)\n",
    "    mix_means[:, :2] = 1\n",
    "\n",
    "    distribution = xshaped_gauss_experiment(\n",
    "        mixture_dist=D.Categorical(torch.ones(mix_means.shape[0], device=device)),\n",
    "        means=mix_means,\n",
    "        correlation=correlation\n",
    "    )\n",
    "\n",
    "\n",
    "    # sample from target (for computing metric)\n",
    "    x_target = distribution.sample((nparticles, )).to(device)\n",
    "    cov = torch.cov(x_target)\n",
    "\n",
    "    # sample from variational density\n",
    "    x_init =  torch.randn(nparticles, *distribution.event_shape).to(device)\n",
    "\n",
    "    \n",
    "    cov = torch.cov(x_target.T)\n",
    "    if args.method in [\"S-SVGD\", \"all\"]:\n",
    "        # sample from variational density\n",
    "        print(\"Running S-SVGD\")\n",
    "        x_init_s_svgd = x_init.clone()\n",
    "        x_s_svgd = x_init_s_svgd.clone().requires_grad_()\n",
    "        s_svgd = SlicedSVGD(distribution, device=device)\n",
    "\n",
    "        start = time.time()\n",
    "        x_s_svgd, metric_s_svgd = s_svgd.fit(\n",
    "            samples=x_s_svgd, \n",
    "            n_epoch=epochs, \n",
    "            lr=args.lr_g,\n",
    "            eps=lr,\n",
    "            save_every=save_every\n",
    "        )\n",
    "    \n",
    "    theta = x_s_svgd\n",
    "    del x_s_svgd\n",
    "    cov_ssvgd = torch.cov(theta.T)\n",
    "    print(torch.linalg.norm(cov - cov_ssvgd))\n",
    "    list_norm_ssvgd.append(torch.linalg.norm(cov - cov_ssvgd))\n",
    "    print(comm_func_eval(theta, x_target)['var_dis'])\n",
    "    list_gr_var_ssvgd.append(comm_func_eval(theta, x_target)['var_dis'])\n",
    "    print(torch.trace(cov - cov_gsvgd))\n",
    "    list_tr_ssvgd.append(torch.trace(cov - cov_ssvgd))\n",
    "    (evals, evecs) = torch.linalg.eig(cov - cov_ssvgd)\n",
    "    print(evals[0])\n",
    "    list_eig_ssvgd.append(evals[0])\n",
    "    del theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = x_s_svgd \n",
    "cov = torch.cov(x_target.T)\n",
    "index_svgd = []\n",
    "samn_svgd = []\n",
    "for i in range(theta.shape[0]):\n",
    "    samn_svgd.append(torch.linalg.norm(theta[i,:].cpu()).item())\n",
    "    index_svgd.append(i)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(index_svgd, samn_svgd, c='blue')\n",
    "\n",
    "cov_ssvgd = torch.cov(theta.T)\n",
    "\n",
    "\n",
    "print(torch.linalg.norm(cov - cov_ssvgd))\n",
    "print(comm_func_eval(theta, x_target))\n",
    "print(torch.trace(cov - cov_ssvgd))\n",
    "(evals, evecs) = torch.linalg.eig(cov - cov_ssvgd)\n",
    "print(evals[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('AG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28e57e6ed411ebe457d9d5e52f3313a26a0295904f732baf128c9b6661c268ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
