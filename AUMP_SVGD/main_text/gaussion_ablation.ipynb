{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.distributions as D\n",
    "\n",
    "from src.svgd import SVGD\n",
    "from src.gsvgd import FullGSVGDBatch\n",
    "from src.kernel import RBF, BatchRBF\n",
    "from src.utils import plot_particles\n",
    "from src.metrics import Metric\n",
    "from src.manifold import Grassmann\n",
    "from src.s_svgd import SlicedSVGD\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--method'], dest='method', nargs=None, const=None, default='all', type=<class 'str'>, choices=None, help='which method to use', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Running xshaped experiment.')\n",
    "parser.add_argument('--dim', type=int, default=100, help='dimension')\n",
    "parser.add_argument('--effdim', type=int, default=-1, help='dimension')\n",
    "parser.add_argument('--lr', type=float,default=0.01, help='learning rate')\n",
    "parser.add_argument('--delta', type=float,default=0.01, help='stepsize for projections')\n",
    "parser.add_argument('--T', type=float, default=1e-4, help='noise multiplier for projections')\n",
    "parser.add_argument('--lr_g', type=float, default=0.1, help='learning rate for g')\n",
    "parser.add_argument('--nparticles', type=int,default=2000, help='no. of particles')\n",
    "parser.add_argument('--epochs', type=int, default=20000,help='no. of epochs')\n",
    "parser.add_argument('--metric', type=str, default=\"energy\", help='distance metric')\n",
    "parser.add_argument('--noise', type=str, default=\"True\", help='whether to add noise')\n",
    "parser.add_argument('--kernel', type=str, default=\"rbf\", help='kernel')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--seed', type=int, default=0, help='random seed')\n",
    "parser.add_argument('--suffix', type=str, default=\"\", help='suffix for res folder')\n",
    "parser.add_argument('--m', type=int, help='no. of projections')\n",
    "parser.add_argument('--save_every', type=int, default=200, help='step intervals to save particles')\n",
    "parser.add_argument('--method', type=str, default=\"all\", help='which method to use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for dim: 100, lr: 0.01, nparticles: 2000\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args([])\n",
    "dim = args.dim\n",
    "lr = args.lr\n",
    "lr_gsvgd = args.lr\n",
    "delta = args.delta\n",
    "T = args.T\n",
    "nparticles = args.nparticles\n",
    "epochs = args.epochs\n",
    "seed = args.seed\n",
    "eff_dims = [args.effdim] if args.effdim > 0 else [1, 2, 5]\n",
    "save_every = args.save_every # save metric values\n",
    "print(f\"Running for dim: {dim}, lr: {lr}, nparticles: {nparticles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f'cuda:{args.gpu}' if args.gpu != -1 else 'cpu')\n",
    "\n",
    "metric = args.metric\n",
    "\n",
    "results_folder = f\"./res/gaussian{args.suffix}/{args.kernel}_epoch{epochs}_lr{lr}_delta{delta}_n{nparticles}_dim{dim}\"\n",
    "results_folder = f\"{results_folder}/seed{seed}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "if args.kernel == \"rbf\":\n",
    "    Kernel = RBF\n",
    "    BatchKernel = BatchRBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Device: {device}\")\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "## target density\n",
    "means = torch.zeros(dim, device=device)\n",
    "cov = torch.eye(dim, device=device)\n",
    "distribution = D.MultivariateNormal(means.to(device), cov)\n",
    "\n",
    "# sample from target (for computing metric)\n",
    "x_target = distribution.sample((nparticles, ))\n",
    "# sample from variational density\n",
    "x_init = 2 + np.sqrt(2) * torch.randn(nparticles, *distribution.event_shape, device=device)\n",
    "# initialize metric\n",
    "metric_fn = Metric(metric=metric, x_init=x_init.clone, x_target=x_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.method == \"SVGD\":\n",
    "    print(\"Running SVGD\")\n",
    "    # sample from variational density\n",
    "    x = x_init.clone().to(device)\n",
    "    kernel = Kernel(method=\"med_heuristic\")\n",
    "    svgd = SVGD(distribution, kernel, optim.Adam([x], lr=lr), device=device)\n",
    "    start = time.time()\n",
    "    svgd.fit(x, epochs, verbose=True, save_every=save_every)\n",
    "    elapsed_time_svgd = time.time() - start\n",
    "\n",
    "    # plot particles\n",
    "    fig_svgd = plot_particles(\n",
    "        x_init.detach(), \n",
    "        x.detach(), \n",
    "        distribution, \n",
    "        d=6.0, \n",
    "        step=0.1, \n",
    "        concat=means[2:],\n",
    "        savedir=results_folder + f\"/svgd.png\"\n",
    "    )\n",
    "\n",
    "    pickle.dump({\"svgd\": svgd.particles}, open(results_folder + \"/particles_svgd.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GSVGD\n",
    "if args.method == \"GSVGD\":\n",
    "    res_gsvgd = [0] * len(eff_dims)\n",
    "    def run_gsvgd(eff_dims):\n",
    "        for i, eff_dim in enumerate(eff_dims):\n",
    "            print(f\"Running GSVGD with eff dim = {eff_dim}\")\n",
    "            m = args.m\n",
    "\n",
    "            print(\"number of projections:\", m)\n",
    "\n",
    "            # sample from variational density\n",
    "            x_init_gsvgd = x_init.clone()\n",
    "            x_gsvgd = x_init_gsvgd.clone()\n",
    "\n",
    "            # kernel_gsvgd = RBF(method=\"med_heuristic\")\n",
    "            kernel_gsvgd = BatchKernel(method=\"med_heuristic\")\n",
    "            optimizer = optim.Adam([x_gsvgd], lr=lr_gsvgd)\n",
    "            manifold = Grassmann(dim, eff_dim)\n",
    "            U = torch.eye(dim).requires_grad_().to(device)\n",
    "            U = U[:, :(m*eff_dim)]\n",
    "\n",
    "            gsvgd = FullGSVGDBatch(\n",
    "                target=distribution,\n",
    "                kernel=kernel_gsvgd,\n",
    "                manifold=manifold,\n",
    "                optimizer=optimizer,\n",
    "                delta=delta,\n",
    "                T=T,\n",
    "                device=device\n",
    "            )\n",
    "            start = time.time()\n",
    "            U, metric_gsvgd = gsvgd.fit(x_gsvgd, U, m, epochs, \n",
    "                verbose=True, save_every=save_every, threshold=0.0001*m)\n",
    "            elapsed_time = time.time() - start\n",
    "\n",
    "            # plot particles\n",
    "            fig_gsvgd = plot_particles(\n",
    "                x_init_gsvgd.detach(), \n",
    "                x_gsvgd.detach(), \n",
    "                distribution, \n",
    "                d=6.0, \n",
    "                step=0.1, \n",
    "                concat=means[2:],\n",
    "                savedir=results_folder + f\"/fullgsvgd_effdim{eff_dim}_lr{lr_gsvgd}_delta{delta}_m{m}_T{T}.png\"\n",
    "            )\n",
    "\n",
    "            # store results\n",
    "            res_gsvgd[i] = {\"init\":x_init_gsvgd, \"final\":x_gsvgd, \"metric\":metric_gsvgd, \n",
    "                \"fig\":fig_gsvgd, \"particles\":gsvgd.particles, \"pam\":gsvgd.pam, \"res\": gsvgd,\n",
    "                \"elapsed_time\": elapsed_time}\n",
    "        return res_gsvgd\n",
    "\n",
    "    res_gsvgd = run_gsvgd(eff_dims)\n",
    "\n",
    "    pickle.dump(\n",
    "        {f\"gsvgd_effdim{d}\": r[\"particles\"] for d, r in zip(eff_dims, res_gsvgd)},\n",
    "        open(results_folder + f\"/particles_gsvgd_m{eff_dims[0]}_M{args.m}.p\", \"wb\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## S-SVGD\n",
    "if args.method == \"S-SVGD\":\n",
    "    print(\"Running S-SVGD\")\n",
    "    # sample from variational density\n",
    "    x_init_s_svgd = x_init.clone()\n",
    "    x_s_svgd = x_init_s_svgd.clone().requires_grad_()\n",
    "    s_svgd = SlicedSVGD(distribution, device=device)\n",
    "\n",
    "    start = time.time()\n",
    "    x_s_svgd, metric_s_svgd = s_svgd.fit(\n",
    "        samples=x_s_svgd, \n",
    "        n_epoch=epochs, \n",
    "        lr=args.lr_g,\n",
    "        eps=lr,\n",
    "        save_every=save_every\n",
    "    )\n",
    "    elapsed_time_s_svgd = time.time() - start\n",
    "\n",
    "    # plot particles\n",
    "    fig_s_svgd = plot_particles(\n",
    "        x_init_s_svgd.detach(), \n",
    "        x_s_svgd.detach(), \n",
    "        distribution, \n",
    "        d=6.0, \n",
    "        step=0.1, \n",
    "        concat=means[2:],\n",
    "        savedir=results_folder + f\"/ssvgd_lr{lr}_lrg{args.lr_g}.png\"\n",
    "    )\n",
    "\n",
    "    pickle.dump({\"s_svgd\": s_svgd.particles}, open(results_folder + \"/particles_s-svgd.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('AG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28e57e6ed411ebe457d9d5e52f3313a26a0295904f732baf128c9b6661c268ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
